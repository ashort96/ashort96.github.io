<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">

    <meta name="author" content="Adam Short">
    
    

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="CS530 - Lecture 5"/>
<meta name="twitter:description" content="Back
Introduction  Programmers want unlimited amounts of memory with low latency Fast memory technology is more expensive per bit than slower memory Solution: organize memory system into a hierarchy  Entire addressable memory space available in largest, slowest memory Incrementally smaller and faster memories, each containing a subset of the memory below it, proceed in steps up toward the processor   Temporal and spatial locality insures that nearly all references can be found in smaller memories  Gives the allusion of a large, fast memory being presented to the processor    Memory Hierarchy Levels  Block (aka line): unit of copying  May be multiple words   If accessed data is present in upper level  Hit: access satisfied by upper level  Hit ratio: hits/accesses     If accessed data is absent  Miss: block copied from lower level  Time taken: miss penalty Miss ratio: misses/accesses = 1 – hit ratio   Then accessed data supplied from upper level    Memory Hierarchy Design  Memory hierarchy design becomes more crucial with recent multi-core processors:  Aggregate peak bandwidth grows with # cores:  Intel Core i7 can generate two references per core per clock Four cores and 3."/>

    <meta property="og:title" content="CS530 - Lecture 5" />
<meta property="og:description" content="Back
Introduction  Programmers want unlimited amounts of memory with low latency Fast memory technology is more expensive per bit than slower memory Solution: organize memory system into a hierarchy  Entire addressable memory space available in largest, slowest memory Incrementally smaller and faster memories, each containing a subset of the memory below it, proceed in steps up toward the processor   Temporal and spatial locality insures that nearly all references can be found in smaller memories  Gives the allusion of a large, fast memory being presented to the processor    Memory Hierarchy Levels  Block (aka line): unit of copying  May be multiple words   If accessed data is present in upper level  Hit: access satisfied by upper level  Hit ratio: hits/accesses     If accessed data is absent  Miss: block copied from lower level  Time taken: miss penalty Miss ratio: misses/accesses = 1 – hit ratio   Then accessed data supplied from upper level    Memory Hierarchy Design  Memory hierarchy design becomes more crucial with recent multi-core processors:  Aggregate peak bandwidth grows with # cores:  Intel Core i7 can generate two references per core per clock Four cores and 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/notes/cs530/lecture5/" />



    
      <base href="/notes/cs530/lecture5/">
    
    <title>
  CS530 - Lecture 5 · Adam Short
</title>

    
      <link rel="canonical" href="/notes/cs530/lecture5/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />
    <link rel="stylesheet" href="/css/site.css">

    
      
      
      <link rel="stylesheet" href="/css/coder.min.67c558d5cd23d0670f9bdc9398c689abf19d54015de4425d591a3c13ad8651db.css" integrity="sha256-Z8VY1c0j0GcPm9yTmMaJq/GdVAFd5EJdWRo8E62GUds=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="/css/coder-inverted.min.b275a7d098cfe39135a5644e9c6d811e77fc4bdeac01e8e339c7d767146340a8.css" integrity="sha256-snWn0JjP45E1pWROnG2BHnf8S96sAejjOcfXZxRjQKg=" crossorigin="anonymous" media="screen" />
      
    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.68.3" />
  </head>

  <body class=" inverted">
    <main class="wrapper">
      <head>
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-146123302-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

</head>

<nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Adam Short
    </a>
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="/teaching">Teaching</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="/publications">Publications</a>
          </li>
        
      
      
    </ul>
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1>CS530 - Lecture 5</h1>
    </header>

    <p><a href="..">Back</a></p>
<h2 id="introduction">Introduction</h2>
<ul>
<li>Programmers want unlimited amounts of memory with low latency</li>
<li>Fast memory technology is more expensive per bit than slower memory</li>
<li>Solution: organize memory system into a hierarchy
<ul>
<li>Entire addressable memory space available in largest, slowest memory</li>
<li>Incrementally smaller and faster memories, each containing a subset of the memory below it, proceed in steps up toward the processor</li>
</ul>
</li>
<li>Temporal and spatial locality insures that nearly all references can be found in smaller memories
<ul>
<li>Gives the allusion of a large, fast memory being presented to the processor</li>
</ul>
</li>
</ul>
<h2 id="memory-hierarchy-levels">Memory Hierarchy Levels</h2>
<ul>
<li>Block (aka line): unit of copying
<ul>
<li>May be multiple words</li>
</ul>
</li>
<li>If accessed data is present in upper level
<ul>
<li>Hit: access satisfied by upper level
<ul>
<li>Hit ratio: hits/accesses</li>
</ul>
</li>
</ul>
</li>
<li>If accessed data is absent
<ul>
<li>Miss: block copied from lower level
<ul>
<li>Time taken: miss penalty</li>
<li>Miss ratio: misses/accesses = 1 – hit ratio</li>
</ul>
</li>
<li>Then accessed data supplied from upper level</li>
</ul>
</li>
</ul>
<h2 id="memory-hierarchy-design">Memory Hierarchy Design</h2>
<ul>
<li>Memory hierarchy design becomes more crucial with recent multi-core processors:
<ul>
<li>Aggregate peak bandwidth grows with # cores:
<ul>
<li>Intel Core i7 can generate two references per core per clock</li>
<li>Four cores and 3.2 GHz clock
<ul>
<li>25.6 billion 64-bit data references/second +12.8 billion 128-bit instruction references= 409.6 GB/s!</li>
</ul>
</li>
<li>DRAM bandwidth is only 6% of this (25 GB/s)</li>
<li>Requires:
<ul>
<li>Multi-port, pipelined caches</li>
<li>Two levels of cache per core</li>
<li>Shared third-level cache on chip</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="random-access-memory-ram">Random Access Memory (RAM)</h2>
<ul>
<li>Key features:
<ul>
<li><!-- raw HTML omitted -->RAM<!-- raw HTML omitted --> is packaged as a chip</li>
<li>Basic storage unit is a <!-- raw HTML omitted -->cell<!-- raw HTML omitted --> (one bit per cell).</li>
<li>Multiple RAM chips form a memory.</li>
</ul>
</li>
<li>Static RAM (<!-- raw HTML omitted -->SRAM<!-- raw HTML omitted -->)
<ul>
<li>Each cell stores bit with a six-transistor circuit.</li>
<li>Retains value indefinitely, as long as it is kept powered.</li>
<li>Relatively insensitive to disturbances such as electrical noise.</li>
<li>Faster and more expensive than DRAM.</li>
</ul>
</li>
<li>Dynamic RAM (<!-- raw HTML omitted -->DRAM<!-- raw HTML omitted -->)
<ul>
<li>Each cell stores bit with a capacitor and transistor.</li>
<li>Value must be refreshed very 10-100ms</li>
<li>Sensitive to disturbances</li>
<li>Slower and cheaper than SRAM</li>
</ul>
</li>
</ul>
<h2 id="nonvolatile-memory">Nonvolatile Memory</h2>
<ul>
<li>DRAM and SRAM are volatile memories
<ul>
<li>Lose information if powered off</li>
</ul>
</li>
<li>Nonvolatile memories retain value even if powered off.
<ul>
<li>Generic name is read-only memory (<!-- raw HTML omitted -->ROM<!-- raw HTML omitted -->).</li>
<li>Misleading because some ROMs can be read and modified.</li>
</ul>
</li>
<li>Types of ROMs
<ul>
<li>Programmable ROM (<!-- raw HTML omitted -->PROM<!-- raw HTML omitted -->)</li>
<li>Erasable programmable ROM (<!-- raw HTML omitted -->EPROM<!-- raw HTML omitted -->)</li>
<li>Electrically erasable PROM (<!-- raw HTML omitted -->EEPROM<!-- raw HTML omitted -->)</li>
<li>Flash memory</li>
</ul>
</li>
<li><!-- raw HTML omitted -->Firmware<!-- raw HTML omitted -->
<ul>
<li>Program stored in a ROM
<ul>
<li>Boot time code, BIOS (basic input/output system)</li>
<li>graphics cards, disk controllers</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="memory-technologies">Memory Technologies</h2>
<ul>
<li>SRAM
<ul>
<li>0.5ns - 2.5ns, $1000-$5000 per GB</li>
</ul>
</li>
<li>DRAM
<ul>
<li>50ns - 70ns, $10-$70 per GB</li>
</ul>
</li>
<li>Magnetic Disk
<ul>
<li>5ms - 20ms, $0.10-$2 per GB</li>
</ul>
</li>
<li>Ideal memory
<ul>
<li>Access time of SRAM</li>
<li>Capacity and cost/GB of disk</li>
</ul>
</li>
</ul>
<h2 id="principle-of-locality">Principle of Locality</h2>
<ul>
<li>Programs access a small proportion of their address space at any time</li>
<li><!-- raw HTML omitted --><strong>Temporal</strong><!-- raw HTML omitted --> locality
<ul>
<li>Items accessed recently are likely to be accessed again soon</li>
<li>e.g., instructions in a loop, induction variables</li>
</ul>
</li>
<li><!-- raw HTML omitted --><strong>Spacial</strong><!-- raw HTML omitted --> locality
<ul>
<li>Items near those accessed recently are likely to be accessed soon</li>
<li>E.g., sequential instruction access, array data</li>
</ul>
</li>
</ul>
<h2 id="taking-advantage-of-locality">Taking Advantage of Locality</h2>
<ul>
<li>Memory hierarchy</li>
<li>Store everything on disk</li>
<li>Copy recently accessed (and nearby) items from disk to smaller DRAM memory
<ul>
<li>Main memory</li>
</ul>
</li>
<li>Copy more recently accessed (and nearby) items from DRAM to smaller SRAM memory
<ul>
<li>Cache memory attached to CPU</li>
</ul>
</li>
</ul>
<h2 id="cache-memory">Cache memory</h2>
<ul>
<li>Cache memory
<ul>
<li>The level of the memory hierarchy closest to the CPU</li>
</ul>
</li>
<li>Given accesses X<!-- raw HTML omitted -->1<!-- raw HTML omitted -->, &hellip;, X<!-- raw HTML omitted -->n–1<!-- raw HTML omitted -->, X<!-- raw HTML omitted -->n<!-- raw HTML omitted --></li>
<li><!-- raw HTML omitted -->How do we know if data is present?<!-- raw HTML omitted --></li>
<li><!-- raw HTML omitted -->Where do we look?<!-- raw HTML omitted --></li>
</ul>
<h2 id="direct-mapped-cache">Direct Mapped Cache</h2>
<ul>
<li>Location determined by address</li>
<li>Direct mapped: only one choice
<ul>
<li>(Block address) modulo (# Blocks in cache)</li>
</ul>
</li>
<li># Blocks is a power of 2</li>
<li>Use low-order address bits</li>
</ul>
<h2 id="tags-and-valid-bits">Tags and valid bits</h2>
<ul>
<li>How do we know which particular block is stored in a cache location?
<ul>
<li>Store block address as well as the data</li>
<li>Actually, only need the high-order bits</li>
<li>Called the tag</li>
</ul>
</li>
<li>What if there is no data in a location?
<ul>
<li>Valid bit: 1 = present, 0 = not present</li>
<li>Initially 0</li>
</ul>
</li>
</ul>
<h2 id="block-size-considerations">Block Size Considerations</h2>
<ul>
<li>Larger blocks should reduce miss rate
<ul>
<li>Due to spatial locality</li>
</ul>
</li>
<li>But in a fixed-sized cache
<ul>
<li>Larger blocks =&gt; fewer of them
<ul>
<li>More competition =&gt; increased miss rate</li>
</ul>
</li>
<li>Larger blocks =&gt; pollution</li>
</ul>
</li>
<li>Larger miss penalty
<ul>
<li>Can override benefit of reduced miss rate</li>
<li>Early restart and critical-word-first can help</li>
</ul>
</li>
</ul>
<h2 id="associative-caches">Associative Caches</h2>
<ul>
<li>Fully associative
<ul>
<li>Allow a given block to go in any cache entry</li>
<li>Requires all entries to be searched at once</li>
<li>Comparator per entry (expensive)</li>
</ul>
</li>
<li><em>n</em>-way set associative
<ul>
<li>Each set contains <em>n</em> entries</li>
<li>Block number determines which set
<ul>
<li>(Block number) modulo (# Sets in cache)</li>
</ul>
</li>
<li>Search all entries in a given set at once</li>
<li><em>n</em> comparators (less expensive)</li>
</ul>
</li>
</ul>
<h2 id="replacement-policy">Replacement Policy</h2>
<ul>
<li>Direct mapped: no choice</li>
<li>Set associative
<ul>
<li>Prefer non-valid entry, if there is one</li>
<li>Otherwise, choose among entries in the set</li>
</ul>
</li>
<li>Least-recently used (LRU)
<ul>
<li>Choose the one unused for the longest time
<ul>
<li>Simple for 2-way, manageable for 4-way, too hard beyond that</li>
</ul>
</li>
</ul>
</li>
<li>Random
<ul>
<li>Gives approximately the same performance as LRU for high associativity</li>
</ul>
</li>
</ul>
<h1 id="hits-vs-misses">Hits vs. Misses</h1>
<ul>
<li>Read hits
<ul>
<li>this is what we want!</li>
</ul>
</li>
<li>Read misses
<ul>
<li>stall the CPU, fetch block from memory, deliver to cache, restart</li>
</ul>
</li>
<li>Write hits:
<ul>
<li>can replace data in cache and memory (write-through)</li>
<li>write the data only into the cache (write-back the cache later)</li>
</ul>
</li>
<li>Write misses:
<ul>
<li>read the entire block into the cache, then write the word</li>
</ul>
</li>
</ul>
<h1 id="cache-misses">Cache misses</h1>
<ul>
<li>On cache hit, CPU proceeds normally</li>
<li>On cache miss
<ul>
<li>Stall the CPU pipeline</li>
<li>Fetch block from next level of hierarchy</li>
<li>Instruction cache miss
<ul>
<li>Restart instruction fetch</li>
</ul>
</li>
<li>Data cache miss
<ul>
<li>Complete data access</li>
</ul>
</li>
</ul>
</li>
</ul>

  </article>
</section>


      </div>

      <footer class="footer">
  <section class="container">
    
    
    
    
  </section>
</footer>

    </main>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-146123302-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  </body>

</html>
